### 数据处理

1. 读取 csv 文件加载数据
2. 按照 `file_id` 进行分组
3. 对 `DataFrameGroupBy` 对象进行迭代
4. 将训练集的 `label` 和拼接 api 序列存储到两个 list 中
5. 将测试集数量和测试集中拼接 api 序列存储到两个 list 中
6. 保存为 pkl 文件

### 读取 pkl 文件

- 训练集

|  名称  |            含义             |  类型   |   规模   |
| :----: | :-------------------------: | :-----: | :------: |
| labels |        病毒所属类别         | ndarray | (13887,) |
| files  | 训练集 api 序列拼接的字符串 |  list   |  13887   |

- 测试集

|    名称    |            含义             | 类型 | 规模  |
| :--------: | :-------------------------: | :--: | :---: |
| file_names |      测试集样本的数量       | list | 12955 |
|  outfiles  | 测试集 api 序列拼接的字符串 | list | 12955 |

### 特征提取（向量化表示）

```python
vectorizer = CountVectorizer(ngram_range=(1, 3))

x_train = vectorizer.fit_transform(files) # (13887, 180858) 
y_train = labels # (13887,)
x_test = vectorizer.transform(outfiles)  # (12955, 180858)
```

### 模型训练

- xgboost

**StratifiedKFold 5折交叉验证**

StratifiedKFold 是对 KFold 的改进，StratfiedFold 考虑分类结果的因素，分出来的训练集和测试集里面结果的比例和原来的数据集里面结果的比例完全相同，以避免因类分布不均衡而使模型效果不佳。

```python
skf = StratifiedKFold(n_splits=5, random_state=4, shuffle=True)
for i, (tr_ind, te_ind) in enumerate(skf.split(x_train, labels)):
    X_train, X_train_label = x_train[tr_ind], labels[tr_ind]
    X_val, X_val_label = x_train[te_ind], labels[te_ind]
```

`i` 表示第几轮，共 5 轮，`tr_ind` 和 `te_ind` 表示随机划分的训练集和测试集对应的索引，`X_train`、`X_train_label` 对应划分出的训练集的输入和输出，`X_val`、`X_val_label` 对应划分出的测试集的输入和输出。

5 轮循环，`tr_ind` 从 2780 到 2775，`te_ind` 从 11107 到 11112

**xgboost 模型训练**

```python
dtrain = xgb.DMatrix(X_train, label=X_train_label)
dtest = xgb.DMatrix(X_val, X_val_label)
dout = xgb.DMatrix(x_test)

param = {'max_depth': 6, 'eta': 0.1, 'eval_metric': 'mlogloss', 'silent': 1, 'objective': 'multi:softprob',
            'num_class': 8, 'subsample': 0.8,
            'colsample_bytree': 0.85}  # 参数

evallist = [(dtrain, 'train'), (dtest, 'val')]  # 测试 , (dtrain, 'train')
num_round = 300  # 循环次数

bst = xgb.train(param, dtrain, num_boost_round=num_round, evals=evallist, early_stopping_rounds=50)

# dtr = xgb.DMatrix(train_features)
pred_val = bst.predict(dtest)
pred_test = bst.predict(dout)

meta_train[te_ind] = pred_val
meta_test += pred_test
```

xgb.DMatrix() 读取数据并转换为 DMatrix 类型

param 进行参数设置

`evals`：这是一个列表，用于对训练过程中进行评估列表中的元素。形式是`evals = [(dtrain,'train'),(dval,'val')]`或者是`evals = [(dtrain,'train')]`，对于第一种情况，它使得我们可以在训练过程中观察验证集的效果

`early_stopping_rounds`：早期停止次数 ，假设为 100，验证集的误差迭代到一定程度在 100 次内不能再继续降低，就停止迭代。这要求 `evals` 里至少有 一个元素，如果有多个，按最后一个去执行。返回的是最后的迭代次数（不是最好的）。如果 `early_stopping_rounds` 存在，则模型会生成三个属性，`bst.best_score`，`bst.best_iteration` 和 `bst.best_ntree_limit`

`num_boost_round`：这是指提升迭代的次数，也就是生成多少基模型

### 结果格式处理

```python
result = meta_test
out = []
for i in range(len(file_names)):
    tmp = []
    a = result[i].tolist()
    # for j in range(len(a)):
    #     a[j] = ("%.5f" % a[j])

    tmp.append(file_names[i])
    tmp.extend(a)
    out.append(tmp)
```

在结果前面加上文件序号

### 结果输出文件

```python
with open("result.csv", "w", newline='') as csvfile:
    writer = csv.writer(csvfile)
    # 先写入columns_name
    writer.writerow(["file_id", "prob0", "prob1", "prob2", "prob3", "prob4", "prob5", "prob6", "prob7"
    # 写入多行用writerows
    writer.writerows(out)
```

